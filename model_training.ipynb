{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "# from skimage.io import imread\n",
    "import os\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('final_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "train_data = pd.get_dummies(train_data, columns=['Sex'])\n",
    "train_data = pd.get_dummies(train_data, columns=['Frontal/Lateral'])\n",
    "train_data = pd.get_dummies(train_data, columns=['AP/PA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>...</th>\n",
       "      <th>Asymmetry</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Sex_Unknown</th>\n",
       "      <th>Frontal/Lateral_Frontal</th>\n",
       "      <th>Frontal/Lateral_Lateral</th>\n",
       "      <th>AP/PA_AP</th>\n",
       "      <th>AP/PA_LL</th>\n",
       "      <th>AP/PA_PA</th>\n",
       "      <th>AP/PA_RL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384764</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596201</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482320</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417489</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368473</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223411</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64538/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557926</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223412</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64539/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704381</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223413</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64540/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516054</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223414 rows × 484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path  Age  No Finding  \\\n",
       "0       CheXpert-v1.0-small/train/patient00001/study1/...   68         1.0   \n",
       "1       CheXpert-v1.0-small/train/patient00002/study2/...   87         NaN   \n",
       "2       CheXpert-v1.0-small/train/patient00002/study1/...   83         NaN   \n",
       "3       CheXpert-v1.0-small/train/patient00002/study1/...   83         NaN   \n",
       "4       CheXpert-v1.0-small/train/patient00003/study1/...   41         NaN   \n",
       "...                                                   ...  ...         ...   \n",
       "223409  CheXpert-v1.0-small/train/patient64537/study2/...   59         NaN   \n",
       "223410  CheXpert-v1.0-small/train/patient64537/study1/...   59         NaN   \n",
       "223411  CheXpert-v1.0-small/train/patient64538/study1/...    0         NaN   \n",
       "223412  CheXpert-v1.0-small/train/patient64539/study1/...    0         NaN   \n",
       "223413  CheXpert-v1.0-small/train/patient64540/study1/...    0         1.0   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  \\\n",
       "0                              NaN           NaN           NaN          NaN   \n",
       "1                              NaN          -1.0           1.0          NaN   \n",
       "2                              NaN           NaN           1.0          NaN   \n",
       "3                              NaN           NaN           1.0          NaN   \n",
       "4                              NaN           NaN           NaN          NaN   \n",
       "...                            ...           ...           ...          ...   \n",
       "223409                         NaN           NaN          -1.0          NaN   \n",
       "223410                         NaN           NaN          -1.0          NaN   \n",
       "223411                         NaN           NaN           NaN          NaN   \n",
       "223412                         NaN           1.0           1.0          NaN   \n",
       "223413                         NaN           NaN           NaN          NaN   \n",
       "\n",
       "        Edema  Consolidation  Pneumonia  ...  Asymmetry  Sex_Female  Sex_Male  \\\n",
       "0         NaN            NaN        NaN  ...   0.384764        True     False   \n",
       "1        -1.0           -1.0        NaN  ...   0.596201        True     False   \n",
       "2         NaN           -1.0        NaN  ...   0.482320        True     False   \n",
       "3         NaN           -1.0        NaN  ...        NaN        True     False   \n",
       "4         1.0            NaN        NaN  ...   0.417489       False      True   \n",
       "...       ...            ...        ...  ...        ...         ...       ...   \n",
       "223409    NaN            NaN        NaN  ...   0.368473       False      True   \n",
       "223410    NaN            NaN        0.0  ...   0.319442       False      True   \n",
       "223411   -1.0            NaN        NaN  ...   0.557926        True     False   \n",
       "223412    NaN            NaN       -1.0  ...   0.704381        True     False   \n",
       "223413    NaN            NaN        NaN  ...   0.516054        True     False   \n",
       "\n",
       "        Sex_Unknown  Frontal/Lateral_Frontal  Frontal/Lateral_Lateral  \\\n",
       "0             False                     True                    False   \n",
       "1             False                     True                    False   \n",
       "2             False                     True                    False   \n",
       "3             False                    False                     True   \n",
       "4             False                     True                    False   \n",
       "...             ...                      ...                      ...   \n",
       "223409        False                     True                    False   \n",
       "223410        False                     True                    False   \n",
       "223411        False                     True                    False   \n",
       "223412        False                     True                    False   \n",
       "223413        False                     True                    False   \n",
       "\n",
       "        AP/PA_AP  AP/PA_LL  AP/PA_PA  AP/PA_RL  \n",
       "0           True     False     False     False  \n",
       "1           True     False     False     False  \n",
       "2           True     False     False     False  \n",
       "3          False     False     False     False  \n",
       "4           True     False     False     False  \n",
       "...          ...       ...       ...       ...  \n",
       "223409      True     False     False     False  \n",
       "223410      True     False     False     False  \n",
       "223411      True     False     False     False  \n",
       "223412      True     False     False     False  \n",
       "223413      True     False     False     False  \n",
       "\n",
       "[223414 rows x 484 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def prepare_data(data, feature_cols, pca=False, pca_components=0.8):\n",
    "    \"\"\"\n",
    "    Prepares data for cross-validation (no train-test split).\n",
    "    Returns:\n",
    "        X: Processed features (numpy array)\n",
    "        y: Encoded labels (numpy array)\n",
    "        encoder: LabelEncoder (for inverse_transform if needed)\n",
    "        imputer: SimpleImputer (for new data)\n",
    "        scaler: StandardScaler (if PCA=True)\n",
    "        pca: PCA object (if PCA=True)\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN in target and select features\n",
    "    data = data.dropna(subset=['Pleural Effusion'])\n",
    "    X = data[feature_cols]\n",
    "    y = data['Pleural Effusion']\n",
    "\n",
    "    # Encode target\n",
    "    encoder = LabelEncoder()\n",
    "    y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "    # Optional PCA pipeline\n",
    "    if pca:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_imputed)\n",
    "        pca_obj = PCA(n_components=pca_components)\n",
    "        X_processed = pca_obj.fit_transform(X_scaled)\n",
    "        print(f\"Explained Variance: {pca_obj.explained_variance_ratio_.sum():.2f}\")\n",
    "        return X_processed, y_encoded, encoder, imputer, scaler, pca_obj\n",
    "\n",
    "    return X_imputed, y_encoded, encoder, imputer, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss\n",
    "\n",
    "def multiclass_brier_score(y_true, y_prob):\n",
    "    \"\"\"Compute Brier score for multi-class problems (one-vs-rest).\"\"\"\n",
    "    n_classes = y_prob.shape[1]\n",
    "    brier_scores = []\n",
    "    for class_idx in range(n_classes):\n",
    "        y_true_binary = (y_true == class_idx).astype(int)\n",
    "        brier_scores.append(brier_score_loss(y_true_binary, y_prob[:, class_idx]))\n",
    "    return np.mean(brier_scores)  # Average across classes\n",
    "\n",
    "def compute_calibration_metrics(y_true, y_prob, n_bins=10):\n",
    "    \"\"\"Compute ECE, MCE, and Brier for multi-class.\"\"\"\n",
    "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
    "    ece, mce = 0.0, 0.0\n",
    "    \n",
    "    # Confidence is max probability, accuracy is whether prediction was correct\n",
    "    confidences = y_prob.max(axis=1)\n",
    "    predictions = np.argmax(y_prob, axis=1)\n",
    "    accuracies = (predictions == y_true).astype(float)\n",
    "    \n",
    "    # Bin by confidence\n",
    "    bin_indices = np.digitize(confidences, bin_edges, right=True) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        mask = bin_indices == i\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        acc = np.mean(accuracies[mask])\n",
    "        conf = np.mean(confidences[mask])\n",
    "        weight = np.sum(mask) / len(y_true)\n",
    "        ece += weight * np.abs(acc - conf)\n",
    "        mce = max(mce, np.abs(acc - conf))\n",
    "    \n",
    "    brier = multiclass_brier_score(y_true, y_prob)  # Updated Brier calculation\n",
    "    return ece, mce, brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def run_xgboost_cv(X, y, n_folds=5, num_class=3):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    auc_scores, acc_scores, ece_scores, mce_scores, brier_scores = [], [], [], [], []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss',\n",
    "            objective='multi:softprob',\n",
    "            num_class=num_class\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_val)  # Shape: (n_samples, n_classes)\n",
    "        \n",
    "        # Compute metrics\n",
    "        auc = roc_auc_score(y_val, y_prob, multi_class='ovr')\n",
    "        acc = accuracy_score(y_val, np.argmax(y_prob, axis=1))\n",
    "        ece, mce, brier = compute_calibration_metrics(y_val, y_prob)\n",
    "        \n",
    "        # Store results\n",
    "        auc_scores.append(auc)\n",
    "        acc_scores.append(acc)\n",
    "        ece_scores.append(ece)\n",
    "        mce_scores.append(mce)\n",
    "        brier_scores.append(brier)\n",
    "    \n",
    "    return {\n",
    "        'AUC': (np.mean(auc_scores), np.std(auc_scores)),\n",
    "        'Accuracy': (np.mean(acc_scores), np.std(acc_scores)),\n",
    "        'ECE': (np.mean(ece_scores), np.std(ece_scores)),\n",
    "        'MCE': (np.mean(mce_scores), np.std(mce_scores)),\n",
    "        'Brier': (np.mean(brier_scores), np.std(brier_scores))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, GlobalAveragePooling2D, Reshape, Conv2D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "# Enable mixed precision for faster training (if GPU available)\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "def build_fast_model(input_shape, num_classes=3):\n",
    "    \"\"\"Optimized architecture for speed and performance\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Input processing\n",
    "    if len(input_shape) == 1:  # Flattened features\n",
    "        x = Dense(128)(inputs)  # Reduced from 256\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Reshape((8, 8, 2))(x)  # Smaller spatial dimensions\n",
    "    else:  # Image input\n",
    "        x = inputs\n",
    "    \n",
    "    # Simplified convolutional blocks\n",
    "    x = Conv2D(32, 3, padding='same')(x)  # Reduced filters\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Stack of efficient residual blocks\n",
    "    for filters in [32, 64, 128]:  # Reduced filter sizes\n",
    "        # Skip connection\n",
    "        shortcut = Conv2D(filters, 1)(x) if x.shape[-1] != filters else x\n",
    "        \n",
    "        # Main path\n",
    "        x = Conv2D(filters, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Add()([x, shortcut])\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "    # Classification head\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(64, activation='relu')(x)  # Reduced units\n",
    "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def run_fast_cv(X, y, num_classes=3, n_folds=5):\n",
    "    \"\"\"Optimized 5-fold CV with all metrics\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    results = {\n",
    "        'AUC': [], 'Accuracy': [], \n",
    "        'ECE': [], 'MCE': [], 'Brier': []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nFold {fold+1}/{n_folds}\")\n",
    "        \n",
    "        # Data split\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Build and train\n",
    "        model = build_fast_model(X_train.shape[1:], num_classes)\n",
    "        model.compile(\n",
    "            optimizer=Adam(0.002),  # Increased learning rate\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=30,  # Reduced epochs\n",
    "            batch_size=64,  # Increased batch size\n",
    "            callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_prob = model.predict(X_val, verbose=0, batch_size=128)  # Larger prediction batch\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        results['AUC'].append(roc_auc_score(y_val, y_prob, multi_class='ovr'))\n",
    "        results['Accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "        \n",
    "        ece, mce, brier = compute_calibration_metrics(y_val, y_prob)\n",
    "        results['ECE'].append(ece)\n",
    "        results['MCE'].append(mce)\n",
    "        results['Brier'].append(brier)\n",
    "        \n",
    "        print(f\"Fold {fold+1} | AUC: {results['AUC'][-1]:.4f} | Time: {history.history['time'][-1]:.1f}s\")\n",
    "    \n",
    "    return {\n",
    "        metric: (np.mean(values), np.std(values))\n",
    "        for metric, values in results.items()\n",
    "    }\n",
    "\n",
    "def compute_calibration_metrics(y_true, y_prob, n_bins=5):  # Reduced bins for speed\n",
    "    \"\"\"Faster calibration metrics calculation\"\"\"\n",
    "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
    "    ece, mce = 0.0, 0.0\n",
    "    \n",
    "    conf = np.max(y_prob, axis=1)\n",
    "    pred = np.argmax(y_prob, axis=1)\n",
    "    acc = (pred == y_true).astype(float)\n",
    "    \n",
    "    bin_indices = np.digitize(conf, bin_edges, right=True) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        mask = bin_indices == i\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        bin_acc = np.mean(acc[mask])\n",
    "        bin_conf = np.mean(conf[mask])\n",
    "        weight = mask.sum() / len(y_true)\n",
    "        ece += weight * np.abs(bin_acc - bin_conf)\n",
    "        mce = max(mce, np.abs(bin_acc - bin_conf))\n",
    "    \n",
    "    # Multi-class Brier score\n",
    "    brier = np.mean([\n",
    "        brier_score_loss((y_true == i).astype(int), y_prob[:, i])\n",
    "        for i in range(y_prob.shape[1])\n",
    "    ])\n",
    "    \n",
    "    return ece, mce, brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['corner_192', 'corner_193', 'corner_194', 'corner_195', 'corner_196',\n",
       "       'corner_197', 'corner_198', 'corner_199', 'Right_Lung_Intensity',\n",
       "       'Left_Lung_Intensity', 'Asymmetry', 'Sex_Female', 'Sex_Male',\n",
       "       'Sex_Unknown', 'Frontal/Lateral_Frontal', 'Frontal/Lateral_Lateral',\n",
       "       'AP/PA_AP', 'AP/PA_LL', 'AP/PA_PA', 'AP/PA_RL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:17:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:17:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:17:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:17:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:17:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: {'AUC': (0.8762353007975443, 0.0015492341947760415), 'Accuracy': (0.845770994853045, 0.0013957687128646706), 'ECE': (0.0049342679151966615, 0.0012160366759434128), 'MCE': (0.05664789311022626, 0.04180863883596941), 'Brier': (0.08071883831944418, 0.0005621965577145979)}\n"
     ]
    }
   ],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "feature_columns =  ['Age', 'No Finding', 'Enlarged Cardiomediastinum',\n",
    "       'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation',\n",
    "       'Pneumonia', 'Atelectasis', 'Pneumothorax',\n",
    "       'Pleural Other', 'Fracture', 'Support Devices', 'Sex_Female', 'Sex_Male',\n",
    "       'Sex_Unknown', 'Frontal/Lateral_Frontal', 'Frontal/Lateral_Lateral',\n",
    "       'AP/PA_AP', 'AP/PA_LL', 'AP/PA_PA', 'AP/PA_RL'] # Modify as needed\n",
    "\n",
    "# Prepare full dataset\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data, \n",
    "    feature_cols=feature_columns, \n",
    "    pca=False  # Set to True if using PCA\n",
    ")\n",
    "\n",
    "# Run 5-fold CV (using the function from earlier)\n",
    "cv_metrics = run_xgboost_cv(X, y, num_class=3)\n",
    "print(\"CV Results:\", cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch 1/30\n",
      "\u001b[1m1666/1666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 87ms/step - accuracy: 0.7364 - loss: 0.6834 - val_accuracy: 0.7012 - val_loss: 0.8291\n",
      "Epoch 2/30\n",
      "\u001b[1m 200/1666\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 78ms/step - accuracy: 0.8007 - loss: 0.5688"
     ]
    }
   ],
   "source": [
    "# Correct way to drop multiple columns\n",
    "feature_columns =  ['Age', 'No Finding', 'Enlarged Cardiomediastinum',\n",
    "       'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation',\n",
    "       'Pneumonia', 'Atelectasis', 'Pneumothorax',\n",
    "       'Pleural Other', 'Fracture', 'Support Devices', 'Sex_Female', 'Sex_Male',\n",
    "       'Sex_Unknown', 'Frontal/Lateral_Frontal', 'Frontal/Lateral_Lateral',\n",
    "       'AP/PA_AP', 'AP/PA_LL', 'AP/PA_PA', 'AP/PA_RL'] # Modify as needed\n",
    "\n",
    "# 1. Prepare your data\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data,\n",
    "    feature_cols=feature_columns,\n",
    "    pca=False\n",
    ")\n",
    "\n",
    "# 2. Run optimized CV\n",
    "cv_results = run_fast_cv(X, y, num_classes=3)\n",
    "\n",
    "# 3. View results\n",
    "print(\"\\nOptimized Model Results:\")\n",
    "for metric, (mean, std) in cv_results.items():\n",
    "    print(f\"{metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST WITHOUT CLINICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:21:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:22:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:22:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:23:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:23:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: {'AUC': (0.8643145485188984, 0.0006820547305408676), 'Accuracy': (0.8389021932890671, 0.0011131276740131738), 'ECE': (0.01010382077930666, 0.0011881417048674743), 'MCE': (0.07259024703723263, 0.04467180402437322), 'Brier': (0.0841902629498664, 0.0004480080338447924)}\n"
     ]
    }
   ],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_no_clinical = train_data.drop(['Pleural Effusion', 'Path','Right_Lung_Intensity', 'Left_Lung_Intensity', 'Asymmetry', ], axis=1)\n",
    "feature_columns = train_data_no_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data, \n",
    "    feature_cols=feature_columns, \n",
    "    pca=False  # Set to True if using PCA\n",
    ")\n",
    "\n",
    "# Run 5-fold CV (using the function from earlier)\n",
    "cv_metrics = run_xgboost_cv(X, y, num_class=3)\n",
    "print(\"CV Results:\", cv_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6283 - loss: 2.5718 - val_accuracy: 0.6470 - val_loss: 0.8434\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6509 - loss: 0.8407 - val_accuracy: 0.6470 - val_loss: 0.8440\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6518 - loss: 0.8357 - val_accuracy: 0.6470 - val_loss: 0.8350\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6503 - loss: 0.8393 - val_accuracy: 0.6470 - val_loss: 0.8232\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6509 - loss: 0.8302 - val_accuracy: 0.6470 - val_loss: 0.8211\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6512 - loss: 0.8301 - val_accuracy: 0.6470 - val_loss: 0.8155\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6536 - loss: 0.8230 - val_accuracy: 0.6553 - val_loss: 0.8121\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6529 - loss: 0.8201 - val_accuracy: 0.6559 - val_loss: 0.8087\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6561 - loss: 0.8173 - val_accuracy: 0.6513 - val_loss: 0.8074\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6580 - loss: 0.8131 - val_accuracy: 0.6596 - val_loss: 0.8056\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6574 - loss: 0.8139 - val_accuracy: 0.6654 - val_loss: 0.8010\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6585 - loss: 0.8135 - val_accuracy: 0.6643 - val_loss: 0.8052\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 0.8159 - val_accuracy: 0.6685 - val_loss: 0.7999\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6592 - loss: 0.8144 - val_accuracy: 0.6602 - val_loss: 0.8046\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.8140 - val_accuracy: 0.6631 - val_loss: 0.8005\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 0.8135 - val_accuracy: 0.6687 - val_loss: 0.8034\n",
      "Epoch 17/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6595 - loss: 0.8118 - val_accuracy: 0.6686 - val_loss: 0.7985\n",
      "Epoch 18/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 0.8137 - val_accuracy: 0.6678 - val_loss: 0.7982\n",
      "Epoch 19/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6576 - loss: 0.8161 - val_accuracy: 0.6628 - val_loss: 0.8013\n",
      "Epoch 20/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6568 - loss: 0.8127 - val_accuracy: 0.6717 - val_loss: 0.8023\n",
      "Epoch 21/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6596 - loss: 0.8102 - val_accuracy: 0.6712 - val_loss: 0.7977\n",
      "Epoch 22/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6578 - loss: 0.8129 - val_accuracy: 0.6599 - val_loss: 0.8028\n",
      "Epoch 23/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6582 - loss: 0.8119 - val_accuracy: 0.6663 - val_loss: 0.8073\n",
      "Epoch 24/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6582 - loss: 0.8141 - val_accuracy: 0.6682 - val_loss: 0.7991\n",
      "Epoch 25/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6592 - loss: 0.8100 - val_accuracy: 0.6560 - val_loss: 0.8050\n",
      "Epoch 26/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6579 - loss: 0.8109 - val_accuracy: 0.6708 - val_loss: 0.7995\n",
      "Fold 1 - AUC: 0.6235, Acc: 0.6712, ECE: 0.0209\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 2.4386 - val_accuracy: 0.6471 - val_loss: 0.8434\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6543 - loss: 0.8358 - val_accuracy: 0.6590 - val_loss: 0.8241\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6524 - loss: 0.8317 - val_accuracy: 0.6470 - val_loss: 0.8321\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6511 - loss: 0.8335 - val_accuracy: 0.6470 - val_loss: 1.0660\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 0.8286 - val_accuracy: 0.6564 - val_loss: 0.8189\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6547 - loss: 0.8229 - val_accuracy: 0.6546 - val_loss: 0.8135\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6567 - loss: 0.8175 - val_accuracy: 0.6660 - val_loss: 0.8122\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 0.8121 - val_accuracy: 0.6671 - val_loss: 0.8047\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6575 - loss: 0.8140 - val_accuracy: 0.6662 - val_loss: 0.8050\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6614 - loss: 0.8104 - val_accuracy: 0.6648 - val_loss: 0.8034\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6597 - loss: 0.8080 - val_accuracy: 0.6706 - val_loss: 0.8023\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6609 - loss: 0.8094 - val_accuracy: 0.6665 - val_loss: 0.8042\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6585 - loss: 0.8113 - val_accuracy: 0.6593 - val_loss: 0.8057\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6619 - loss: 0.8068 - val_accuracy: 0.6677 - val_loss: 0.8027\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6616 - loss: 0.8066 - val_accuracy: 0.6690 - val_loss: 0.8028\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6622 - loss: 0.8089 - val_accuracy: 0.6652 - val_loss: 0.8062\n",
      "Fold 2 - AUC: 0.6234, Acc: 0.6706, ECE: 0.0078\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 2.4711 - val_accuracy: 0.6471 - val_loss: 0.8307\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 0.8395 - val_accuracy: 0.6478 - val_loss: 0.8365\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6499 - loss: 0.8378 - val_accuracy: 0.6539 - val_loss: 0.8229\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6516 - loss: 0.8304 - val_accuracy: 0.6588 - val_loss: 0.8293\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6534 - loss: 0.8285 - val_accuracy: 0.6513 - val_loss: 0.8284\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6524 - loss: 0.8289 - val_accuracy: 0.6668 - val_loss: 0.8095\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6536 - loss: 0.8227 - val_accuracy: 0.6625 - val_loss: 0.8068\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6605 - loss: 0.8087 - val_accuracy: 0.6632 - val_loss: 0.8055\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6568 - loss: 0.8160 - val_accuracy: 0.6659 - val_loss: 0.8038\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6586 - loss: 0.8121 - val_accuracy: 0.6626 - val_loss: 0.8044\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6573 - loss: 0.8130 - val_accuracy: 0.6653 - val_loss: 0.8045\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6591 - loss: 0.8109 - val_accuracy: 0.6643 - val_loss: 0.8047\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6606 - loss: 0.8091 - val_accuracy: 0.6609 - val_loss: 0.8071\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6577 - loss: 0.8130 - val_accuracy: 0.6606 - val_loss: 0.8049\n",
      "Fold 3 - AUC: 0.6213, Acc: 0.6659, ECE: 0.0148\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 2.5193 - val_accuracy: 0.6500 - val_loss: 0.8410\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6497 - loss: 0.8395 - val_accuracy: 0.6414 - val_loss: 0.8308\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: 0.8363 - val_accuracy: 0.6470 - val_loss: 0.8301\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6532 - loss: 0.8310 - val_accuracy: 0.6470 - val_loss: 0.8271\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 0.8282 - val_accuracy: 0.6469 - val_loss: 0.8278\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6566 - loss: 0.8218 - val_accuracy: 0.6515 - val_loss: 0.8199\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6539 - loss: 0.8202 - val_accuracy: 0.6576 - val_loss: 0.8191\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6547 - loss: 0.8167 - val_accuracy: 0.6656 - val_loss: 0.8103\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6573 - loss: 0.8149 - val_accuracy: 0.6566 - val_loss: 0.8088\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6561 - loss: 0.8143 - val_accuracy: 0.6593 - val_loss: 0.8108\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6573 - loss: 0.8147 - val_accuracy: 0.6655 - val_loss: 0.8032\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6587 - loss: 0.8117 - val_accuracy: 0.6668 - val_loss: 0.8055\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 0.8110 - val_accuracy: 0.6635 - val_loss: 0.8063\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 0.8094 - val_accuracy: 0.6681 - val_loss: 0.8040\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6590 - loss: 0.8106 - val_accuracy: 0.6648 - val_loss: 0.8048\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 0.8104 - val_accuracy: 0.6657 - val_loss: 0.8038\n",
      "Fold 4 - AUC: 0.6265, Acc: 0.6655, ECE: 0.0070\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6301 - loss: 2.4575 - val_accuracy: 0.6470 - val_loss: 0.8247\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6503 - loss: 0.8391 - val_accuracy: 0.6611 - val_loss: 0.8284\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6486 - loss: 0.8393 - val_accuracy: 0.6365 - val_loss: 0.8446\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6476 - loss: 0.8412 - val_accuracy: 0.6537 - val_loss: 0.8389\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6502 - loss: 0.8329 - val_accuracy: 0.6574 - val_loss: 0.8208\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6534 - loss: 0.8267 - val_accuracy: 0.6594 - val_loss: 0.8088\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6533 - loss: 0.8207 - val_accuracy: 0.6497 - val_loss: 0.8191\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6559 - loss: 0.8164 - val_accuracy: 0.6612 - val_loss: 0.8055\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6583 - loss: 0.8141 - val_accuracy: 0.6654 - val_loss: 0.8046\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 0.8105 - val_accuracy: 0.6625 - val_loss: 0.8027\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.8160 - val_accuracy: 0.6671 - val_loss: 0.8103\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6572 - loss: 0.8130 - val_accuracy: 0.6652 - val_loss: 0.8019\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6588 - loss: 0.8116 - val_accuracy: 0.6690 - val_loss: 0.8009\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6599 - loss: 0.8120 - val_accuracy: 0.6680 - val_loss: 0.7995\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 0.8120 - val_accuracy: 0.6678 - val_loss: 0.8045\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 0.8135 - val_accuracy: 0.6683 - val_loss: 0.8010\n",
      "Epoch 17/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6583 - loss: 0.8154 - val_accuracy: 0.6710 - val_loss: 0.8029\n",
      "Epoch 18/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 0.8107 - val_accuracy: 0.6653 - val_loss: 0.8028\n",
      "Epoch 19/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6572 - loss: 0.8135 - val_accuracy: 0.6599 - val_loss: 0.8063\n",
      "Fold 5 - AUC: 0.6241, Acc: 0.6680, ECE: 0.0137\n",
      "CV Results: {'AUC': (0.6237452800031662, 0.001669194548317317), 'Accuracy': (0.6682480954267902, 0.0023498636653970697), 'ECE': (0.012860218400780082, 0.005097957536121629), 'MCE': (0.02614617555992286, 0.007814602615837217), 'Brier': (0.1548262819783324, 0.0005932939453506192)}\n"
     ]
    }
   ],
   "source": [
    "train_data_no_clinical = train_data.drop(['Pleural Effusion', 'Path','Right_Lung_Intensity', 'Left_Lung_Intensity', 'Asymmetry', ], axis=1)\n",
    "feature_columns = train_data_no_clinical.columns  # Modify as needed\n",
    "\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data,\n",
    "    feature_cols=feature_columns,\n",
    "    pca=False\n",
    ")\n",
    "\n",
    "# 2. Run robust 5-fold cross-validation\n",
    "cv_results = run_robust_cv(X, y, num_classes=3)\n",
    "\n",
    "# 3. View comprehensive results\n",
    "print(\"\\nFinal Robust Model CV Results:\")\n",
    "for metric, (mean, std) in sorted(cv_results.items()):\n",
    "    print(f\"{metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST WITH CLINICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:27:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:28:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:28:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:29:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [00:30:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: {'AUC': (0.8701672046997343, 0.0010127902693060672), 'Accuracy': (0.8418373838498505, 0.0011894381820696546), 'ECE': (0.009779595511506619, 0.0014650473499585096), 'MCE': (0.037831661027525644, 0.008845112620963042), 'Brier': (0.08273710357479687, 0.0005258635607662919)}\n"
     ]
    }
   ],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_clinical = train_data.drop(['Pleural Effusion', 'Path'], axis=1)\n",
    "feature_columns = train_data_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data, \n",
    "    feature_cols=feature_columns, \n",
    "    pca=False  # Set to True if using PCA\n",
    ")\n",
    "\n",
    "# Run 5-fold CV (using the function from earlier)\n",
    "cv_metrics = run_xgboost_cv(X, y, num_class=3)\n",
    "print(\"CV Results:\", cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6292 - loss: 2.4352 - val_accuracy: 0.6608 - val_loss: 0.8186\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6576 - loss: 0.8287 - val_accuracy: 0.6470 - val_loss: 0.8175\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6657 - loss: 0.8103 - val_accuracy: 0.6777 - val_loss: 0.7923\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.7975 - val_accuracy: 0.6811 - val_loss: 0.7887\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6715 - loss: 0.7933 - val_accuracy: 0.6816 - val_loss: 0.7817\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6726 - loss: 0.7864 - val_accuracy: 0.6792 - val_loss: 0.7774\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6731 - loss: 0.7853 - val_accuracy: 0.6873 - val_loss: 0.7702\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6738 - loss: 0.7847 - val_accuracy: 0.6865 - val_loss: 0.7707\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6780 - loss: 0.7811 - val_accuracy: 0.6866 - val_loss: 0.7718\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6747 - loss: 0.7825 - val_accuracy: 0.6714 - val_loss: 0.7868\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6783 - loss: 0.7758 - val_accuracy: 0.6904 - val_loss: 0.7652\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.7765 - val_accuracy: 0.6900 - val_loss: 0.7655\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6773 - loss: 0.7792 - val_accuracy: 0.6774 - val_loss: 0.7678\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6766 - loss: 0.7761 - val_accuracy: 0.6867 - val_loss: 0.7614\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.7812 - val_accuracy: 0.6884 - val_loss: 0.7648\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6786 - loss: 0.7769 - val_accuracy: 0.6905 - val_loss: 0.7591\n",
      "Epoch 17/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.7789 - val_accuracy: 0.6855 - val_loss: 0.7678\n",
      "Epoch 18/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6759 - loss: 0.7806 - val_accuracy: 0.6819 - val_loss: 0.7640\n",
      "Epoch 19/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6782 - loss: 0.7770 - val_accuracy: 0.6885 - val_loss: 0.7615\n",
      "Epoch 20/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6758 - loss: 0.7790 - val_accuracy: 0.6823 - val_loss: 0.7642\n",
      "Epoch 21/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 0.7732 - val_accuracy: 0.6897 - val_loss: 0.7605\n",
      "Fold 1 - AUC: 0.6769, Acc: 0.6905, ECE: 0.0121\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.6325 - loss: 2.5644 - val_accuracy: 0.6471 - val_loss: 0.8354\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6567 - loss: 0.8313 - val_accuracy: 0.6641 - val_loss: 0.8148\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6628 - loss: 0.8147 - val_accuracy: 0.6812 - val_loss: 0.7904\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6658 - loss: 0.8066 - val_accuracy: 0.6830 - val_loss: 0.7788\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6674 - loss: 0.7975 - val_accuracy: 0.6766 - val_loss: 0.7860\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6695 - loss: 0.7928 - val_accuracy: 0.6665 - val_loss: 0.8194\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6723 - loss: 0.7859 - val_accuracy: 0.6880 - val_loss: 0.7780\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6725 - loss: 0.7850 - val_accuracy: 0.6853 - val_loss: 0.7735\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.7811 - val_accuracy: 0.6802 - val_loss: 0.7821\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6736 - loss: 0.7819 - val_accuracy: 0.6827 - val_loss: 0.7713\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.7824 - val_accuracy: 0.6883 - val_loss: 0.7645\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.7798 - val_accuracy: 0.6859 - val_loss: 0.7687\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6770 - loss: 0.7791 - val_accuracy: 0.6848 - val_loss: 0.7680\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6777 - loss: 0.7786 - val_accuracy: 0.6795 - val_loss: 0.7719\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.7769 - val_accuracy: 0.6804 - val_loss: 0.7665\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.7791 - val_accuracy: 0.6855 - val_loss: 0.7680\n",
      "Fold 2 - AUC: 0.6782, Acc: 0.6883, ECE: 0.0072\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.6378 - loss: 2.4426 - val_accuracy: 0.6560 - val_loss: 0.8183\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6585 - loss: 0.8256 - val_accuracy: 0.6763 - val_loss: 0.8016\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.8130 - val_accuracy: 0.6470 - val_loss: 0.7943\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6708 - loss: 0.7989 - val_accuracy: 0.6704 - val_loss: 0.7852\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6743 - loss: 0.7940 - val_accuracy: 0.6865 - val_loss: 0.7686\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6747 - loss: 0.7859 - val_accuracy: 0.6739 - val_loss: 0.7793\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6743 - loss: 0.7830 - val_accuracy: 0.6746 - val_loss: 0.7846\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6767 - loss: 0.7776 - val_accuracy: 0.6831 - val_loss: 0.7744\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6754 - loss: 0.7790 - val_accuracy: 0.6825 - val_loss: 0.7723\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6769 - loss: 0.7775 - val_accuracy: 0.6790 - val_loss: 0.7726\n",
      "Fold 3 - AUC: 0.6767, Acc: 0.6865, ECE: 0.0152\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.6395 - loss: 2.3329 - val_accuracy: 0.6620 - val_loss: 0.8247\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6605 - loss: 0.8246 - val_accuracy: 0.6475 - val_loss: 0.8244\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6684 - loss: 0.8119 - val_accuracy: 0.6617 - val_loss: 0.7975\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6716 - loss: 0.8008 - val_accuracy: 0.6796 - val_loss: 0.7882\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6722 - loss: 0.7911 - val_accuracy: 0.6599 - val_loss: 0.8061\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.7889 - val_accuracy: 0.6861 - val_loss: 0.7698\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6788 - loss: 0.7793 - val_accuracy: 0.6873 - val_loss: 0.7669\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6783 - loss: 0.7782 - val_accuracy: 0.6748 - val_loss: 0.7773\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6784 - loss: 0.7779 - val_accuracy: 0.6817 - val_loss: 0.7759\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6786 - loss: 0.7777 - val_accuracy: 0.6821 - val_loss: 0.7671\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.7757 - val_accuracy: 0.6784 - val_loss: 0.7744\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6789 - loss: 0.7783 - val_accuracy: 0.6838 - val_loss: 0.7707\n",
      "Fold 4 - AUC: 0.6717, Acc: 0.6873, ECE: 0.0131\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.6299 - loss: 2.4458 - val_accuracy: 0.6699 - val_loss: 0.8268\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6586 - loss: 0.8270 - val_accuracy: 0.6472 - val_loss: 0.8417\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6615 - loss: 0.8174 - val_accuracy: 0.6858 - val_loss: 0.8079\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6667 - loss: 0.8054 - val_accuracy: 0.6886 - val_loss: 0.7803\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6702 - loss: 0.7956 - val_accuracy: 0.6748 - val_loss: 0.7793\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6709 - loss: 0.7874 - val_accuracy: 0.6854 - val_loss: 0.7673\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6727 - loss: 0.7856 - val_accuracy: 0.6903 - val_loss: 0.7696\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.7823 - val_accuracy: 0.6712 - val_loss: 0.7710\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6745 - loss: 0.7793 - val_accuracy: 0.6872 - val_loss: 0.7696\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.7797 - val_accuracy: 0.6880 - val_loss: 0.7641\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6723 - loss: 0.7817 - val_accuracy: 0.6751 - val_loss: 0.7672\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6736 - loss: 0.7786 - val_accuracy: 0.6869 - val_loss: 0.7646\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6776 - loss: 0.7781 - val_accuracy: 0.6896 - val_loss: 0.7621\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6784 - loss: 0.7761 - val_accuracy: 0.6838 - val_loss: 0.7716\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.7809 - val_accuracy: 0.6774 - val_loss: 0.7654\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6777 - loss: 0.7798 - val_accuracy: 0.6865 - val_loss: 0.7626\n",
      "Epoch 17/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.7801 - val_accuracy: 0.6911 - val_loss: 0.7641\n",
      "Epoch 18/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6735 - loss: 0.7810 - val_accuracy: 0.6840 - val_loss: 0.7712\n",
      "Fold 5 - AUC: 0.6752, Acc: 0.6896, ECE: 0.0250\n",
      "CV Results: {'AUC': (0.6757417288846039, 0.002227892757502965), 'Accuracy': (0.6884191092051218, 0.0014407104998269327), 'ECE': (0.014509191319966872, 0.0058716536931705515), 'MCE': (0.03066576329620323, 0.007016033308591207), 'Brier': (0.14490313018489182, 0.000544855609457797)}\n"
     ]
    }
   ],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_clinical = train_data.drop(['Pleural Effusion', 'Path'], axis=1)\n",
    "feature_columns = train_data_clinical.columns  # Modify as needed\n",
    "\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data,\n",
    "    feature_cols=feature_columns,\n",
    "    pca=False\n",
    ")\n",
    "\n",
    "# 2. Run robust 5-fold cross-validation\n",
    "cv_results = run_robust_cv(X, y, num_classes=3)\n",
    "\n",
    "# 3. View comprehensive results\n",
    "print(\"\\nFinal Robust Model CV Results:\")\n",
    "for metric, (mean, std) in sorted(cv_results.items()):\n",
    "    print(f\"{metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats + Clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [01:12:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [01:12:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [01:12:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [01:12:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [01:12:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: {'AUC': (0.8722005686867729, 0.0013585147939188939), 'Accuracy': (0.8429784277739873, 0.0016597529627462371), 'ECE': (0.005762527009482558, 0.0010061351053880696), 'MCE': (0.05721774783752951, 0.0364422951008462), 'Brier': (0.08213836406735485, 0.0006741073160065653)}\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [col for col in train_data.columns if col.startswith(('hist', 'cornr'))]\n",
    "train_data_stats_clinical = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Correct way to drop multiple columns\n",
    "train_data_stats_clinical = train_data_stats_clinical.drop(['Pleural Effusion', 'Path'], axis=1)\n",
    "feature_columns = train_data_stats_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data, \n",
    "    feature_cols=feature_columns, \n",
    "    pca=False  # Set to True if using PCA\n",
    ")\n",
    "\n",
    "# Run 5-fold CV (using the function from earlier)\n",
    "cv_metrics = run_xgboost_cv(X, y, num_class=3)\n",
    "print(\"CV Results:\", cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.6279 - loss: 2.3950 - val_accuracy: 0.6667 - val_loss: 0.8244\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6538 - loss: 0.8326 - val_accuracy: 0.6470 - val_loss: 0.8155\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6589 - loss: 0.8207 - val_accuracy: 0.6490 - val_loss: 0.8070\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6655 - loss: 0.8025 - val_accuracy: 0.6470 - val_loss: 0.7858\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6740 - loss: 0.7966 - val_accuracy: 0.6863 - val_loss: 0.7826\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6721 - loss: 0.7881 - val_accuracy: 0.6846 - val_loss: 0.7728\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6743 - loss: 0.7878 - val_accuracy: 0.6853 - val_loss: 0.7702\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6740 - loss: 0.7825 - val_accuracy: 0.6898 - val_loss: 0.7588\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.7823 - val_accuracy: 0.6919 - val_loss: 0.7633\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6735 - loss: 0.7817 - val_accuracy: 0.6803 - val_loss: 0.7727\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.7797 - val_accuracy: 0.6889 - val_loss: 0.7613\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.7787 - val_accuracy: 0.6888 - val_loss: 0.7623\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6739 - loss: 0.7809 - val_accuracy: 0.6857 - val_loss: 0.7669\n",
      "Fold 1 - AUC: 0.6856, Acc: 0.6898, ECE: 0.0236\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6300 - loss: 2.5297 - val_accuracy: 0.6470 - val_loss: 0.8552\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6539 - loss: 0.8338 - val_accuracy: 0.6501 - val_loss: 0.8042\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6627 - loss: 0.8171 - val_accuracy: 0.6639 - val_loss: 0.7938\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6672 - loss: 0.8007 - val_accuracy: 0.6780 - val_loss: 0.7818\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6715 - loss: 0.7929 - val_accuracy: 0.6812 - val_loss: 0.7786\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6738 - loss: 0.7858 - val_accuracy: 0.6743 - val_loss: 0.7797\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6737 - loss: 0.7843 - val_accuracy: 0.6832 - val_loss: 0.7703\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.7823 - val_accuracy: 0.6759 - val_loss: 0.7775\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6759 - loss: 0.7808 - val_accuracy: 0.6892 - val_loss: 0.7682\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.7803 - val_accuracy: 0.6742 - val_loss: 0.7858\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.7795 - val_accuracy: 0.6626 - val_loss: 0.7778\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.7775 - val_accuracy: 0.6840 - val_loss: 0.7710\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6789 - loss: 0.7762 - val_accuracy: 0.6810 - val_loss: 0.7727\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6773 - loss: 0.7762 - val_accuracy: 0.6835 - val_loss: 0.7712\n",
      "Fold 2 - AUC: 0.6717, Acc: 0.6892, ECE: 0.0058\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6301 - loss: 2.4903 - val_accuracy: 0.6695 - val_loss: 0.8212\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6556 - loss: 0.8316 - val_accuracy: 0.6509 - val_loss: 0.8115\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6640 - loss: 0.8097 - val_accuracy: 0.6798 - val_loss: 0.7977\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6689 - loss: 0.8030 - val_accuracy: 0.6837 - val_loss: 0.7856\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6716 - loss: 0.7927 - val_accuracy: 0.6793 - val_loss: 0.7808\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6708 - loss: 0.7881 - val_accuracy: 0.6759 - val_loss: 0.7742\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6730 - loss: 0.7823 - val_accuracy: 0.6864 - val_loss: 0.7684\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6745 - loss: 0.7808 - val_accuracy: 0.6867 - val_loss: 0.7660\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.7775 - val_accuracy: 0.6756 - val_loss: 0.7719\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6748 - loss: 0.7780 - val_accuracy: 0.6869 - val_loss: 0.7722\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 0.7736 - val_accuracy: 0.6769 - val_loss: 0.7760\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6800 - loss: 0.7749 - val_accuracy: 0.6865 - val_loss: 0.7653\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.7802 - val_accuracy: 0.6749 - val_loss: 0.7751\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6784 - loss: 0.7732 - val_accuracy: 0.6852 - val_loss: 0.7727\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.7748 - val_accuracy: 0.6865 - val_loss: 0.7704\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6783 - loss: 0.7739 - val_accuracy: 0.6886 - val_loss: 0.7661\n",
      "Epoch 17/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 0.7716 - val_accuracy: 0.6793 - val_loss: 0.7703\n",
      "Fold 3 - AUC: 0.6773, Acc: 0.6865, ECE: 0.0152\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6246 - loss: 2.4039 - val_accuracy: 0.6573 - val_loss: 0.8552\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6602 - loss: 0.8293 - val_accuracy: 0.6464 - val_loss: 0.8400\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.8172 - val_accuracy: 0.6741 - val_loss: 0.7905\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6681 - loss: 0.7989 - val_accuracy: 0.6674 - val_loss: 0.7954\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6727 - loss: 0.7907 - val_accuracy: 0.6550 - val_loss: 0.7974\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6723 - loss: 0.7856 - val_accuracy: 0.6808 - val_loss: 0.7764\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6783 - loss: 0.7818 - val_accuracy: 0.6685 - val_loss: 0.7842\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6785 - loss: 0.7789 - val_accuracy: 0.6781 - val_loss: 0.7740\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6758 - loss: 0.7794 - val_accuracy: 0.6871 - val_loss: 0.7706\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.7811 - val_accuracy: 0.6799 - val_loss: 0.7705\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.7795 - val_accuracy: 0.6846 - val_loss: 0.7693\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6735 - loss: 0.7818 - val_accuracy: 0.6822 - val_loss: 0.7721\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.7759 - val_accuracy: 0.6782 - val_loss: 0.7704\n",
      "Epoch 14/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6777 - loss: 0.7780 - val_accuracy: 0.6820 - val_loss: 0.7676\n",
      "Epoch 15/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6801 - loss: 0.7754 - val_accuracy: 0.6812 - val_loss: 0.7676\n",
      "Epoch 16/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.7758 - val_accuracy: 0.6804 - val_loss: 0.7697\n",
      "Epoch 17/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6801 - loss: 0.7755 - val_accuracy: 0.6702 - val_loss: 0.7874\n",
      "Epoch 18/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6770 - loss: 0.7802 - val_accuracy: 0.6819 - val_loss: 0.7690\n",
      "Epoch 19/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6761 - loss: 0.7768 - val_accuracy: 0.6656 - val_loss: 0.7908\n",
      "Fold 4 - AUC: 0.6731, Acc: 0.6820, ECE: 0.0138\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6256 - loss: 2.5733 - val_accuracy: 0.6700 - val_loss: 0.8261\n",
      "Epoch 2/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6558 - loss: 0.8303 - val_accuracy: 0.6769 - val_loss: 0.8173\n",
      "Epoch 3/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6609 - loss: 0.8197 - val_accuracy: 0.6843 - val_loss: 0.7822\n",
      "Epoch 4/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6687 - loss: 0.8026 - val_accuracy: 0.6756 - val_loss: 0.7814\n",
      "Epoch 5/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 0.7955 - val_accuracy: 0.6841 - val_loss: 0.7822\n",
      "Epoch 6/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.7895 - val_accuracy: 0.6893 - val_loss: 0.7655\n",
      "Epoch 7/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 0.7824 - val_accuracy: 0.6850 - val_loss: 0.7702\n",
      "Epoch 8/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6727 - loss: 0.7852 - val_accuracy: 0.6900 - val_loss: 0.7601\n",
      "Epoch 9/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6759 - loss: 0.7821 - val_accuracy: 0.6806 - val_loss: 0.7698\n",
      "Epoch 10/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6761 - loss: 0.7787 - val_accuracy: 0.6936 - val_loss: 0.7609\n",
      "Epoch 11/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.7775 - val_accuracy: 0.6743 - val_loss: 0.7727\n",
      "Epoch 12/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.7776 - val_accuracy: 0.6885 - val_loss: 0.7614\n",
      "Epoch 13/50\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6766 - loss: 0.7772 - val_accuracy: 0.6912 - val_loss: 0.7614\n",
      "Fold 5 - AUC: 0.6779, Acc: 0.6900, ECE: 0.0161\n",
      "CV Results: {'AUC': (0.6770997383405473, 0.004859317516620581), 'Accuracy': (0.6875032668364279, 0.0030387590928972587), 'ECE': (0.014909711883034239, 0.005683762760255097), 'MCE': (0.03205538560821688, 0.005924106060227501), 'Brier': (0.14512780588368573, 0.0009608888877178325)}\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [col for col in train_data.columns if col.startswith(('hist', 'cornr'))]\n",
    "train_data_stats_clinical = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Correct way to drop multiple columns\n",
    "train_data_stats_clinical = train_data_stats_clinical.drop(['Pleural Effusion', 'Path'], axis=1)\n",
    "feature_columns = train_data_stats_clinical.columns  # Modify as needed\n",
    "\n",
    "X, y, encoder, imputer, scaler, pca_obj = prepare_data(\n",
    "    train_data,\n",
    "    feature_cols=feature_columns,\n",
    "    pca=False\n",
    ")\n",
    "\n",
    "# 2. Run robust 5-fold cross-validation\n",
    "cv_results = run_robust_cv(X, y, num_classes=3)\n",
    "\n",
    "# 3. View comprehensive results\n",
    "print(\"\\nFinal Robust Model CV Results:\")\n",
    "for metric, (mean, std) in sorted(cv_results.items()):\n",
    "    print(f\"{metric}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: 0.8007593809582833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabizhelyazkova/anaconda3/envs/Base/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUC: 0.8036028588339875\n"
     ]
    }
   ],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_clinical = train_data.drop(['Pleural Effusion', 'Path'], axis=1)\n",
    "feature_columns = train_data_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test = prepare_data(train_data, feature_columns, pca=True)\n",
    "\n",
    "# Run XGBoost experiment\n",
    "xgb_auc = run_xgboost_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# For ResNet, ensure you have the appropriate setup or use another suitable model\n",
    "# resnet_auc = run_resnet_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"XGBoost AUC:\", xgb_auc)\n",
    "# print(\"ResNet AUC:\", resnet_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = train_predict_evaluate_resnet(X_train, y_train, X_test, y_test)\n",
    "print(\"ResNet Model AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_no_clinical = train_data.drop(['Pleural Effusion', 'Path','Right_Lung_Intensity', 'Left_Lung_Intensity', 'Asymmetry', ], axis=1)\n",
    "feature_columns = train_data_no_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test = prepare_data(train_data, feature_columns, pca=True)\n",
    "\n",
    "# Run XGBoost experiment\n",
    "xgb_auc = run_xgboost_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"XGBoost AUC:\", xgb_auc)\n",
    "# print(\"ResNet AUC:\", resnet_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = train_predict_evaluate_resnet(X_train, y_train, X_test, y_test)\n",
    "print(\"ResNet Model AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
