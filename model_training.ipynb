{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "# from skimage.io import imread\n",
    "import os\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('final_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[train_data['Pleural Effusion'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>...</th>\n",
       "      <th>corner_193</th>\n",
       "      <th>corner_194</th>\n",
       "      <th>corner_195</th>\n",
       "      <th>corner_196</th>\n",
       "      <th>corner_197</th>\n",
       "      <th>corner_198</th>\n",
       "      <th>corner_199</th>\n",
       "      <th>Right_Lung_Intensity</th>\n",
       "      <th>Left_Lung_Intensity</th>\n",
       "      <th>Asymmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>87</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.128293</td>\n",
       "      <td>96.570501</td>\n",
       "      <td>0.596201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.388532</td>\n",
       "      <td>75.504396</td>\n",
       "      <td>0.270156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.260511</td>\n",
       "      <td>79.038964</td>\n",
       "      <td>0.225228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>75</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.301345</td>\n",
       "      <td>94.698435</td>\n",
       "      <td>0.285247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.932217</td>\n",
       "      <td>61.532157</td>\n",
       "      <td>0.267634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>61</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.463986</td>\n",
       "      <td>76.111103</td>\n",
       "      <td>0.727078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.346834</td>\n",
       "      <td>91.663944</td>\n",
       "      <td>0.368473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.248186</td>\n",
       "      <td>95.215829</td>\n",
       "      <td>0.319442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133211 rows × 478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path     Sex  Age  \\\n",
       "1       CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
       "5       CheXpert-v1.0-small/train/patient00004/study1/...  Female   20   \n",
       "6       CheXpert-v1.0-small/train/patient00004/study1/...  Female   20   \n",
       "7       CheXpert-v1.0-small/train/patient00005/study1/...    Male   33   \n",
       "8       CheXpert-v1.0-small/train/patient00005/study1/...    Male   33   \n",
       "...                                                   ...     ...  ...   \n",
       "223403  CheXpert-v1.0-small/train/patient64533/study1/...    Male   75   \n",
       "223405  CheXpert-v1.0-small/train/patient64534/study1/...    Male   63   \n",
       "223407  CheXpert-v1.0-small/train/patient64536/study2/...  Female   61   \n",
       "223409  CheXpert-v1.0-small/train/patient64537/study2/...    Male   59   \n",
       "223410  CheXpert-v1.0-small/train/patient64537/study1/...    Male   59   \n",
       "\n",
       "       Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  \\\n",
       "1              Frontal    AP         NaN                         NaN   \n",
       "5              Frontal    PA         1.0                         0.0   \n",
       "6              Lateral   NaN         1.0                         0.0   \n",
       "7              Frontal    PA         1.0                         NaN   \n",
       "8              Lateral   NaN         1.0                         NaN   \n",
       "...                ...   ...         ...                         ...   \n",
       "223403         Frontal    AP         NaN                         NaN   \n",
       "223405         Frontal    AP         NaN                         NaN   \n",
       "223407         Frontal    AP         NaN                         NaN   \n",
       "223409         Frontal    AP         NaN                         NaN   \n",
       "223410         Frontal    AP         NaN                         NaN   \n",
       "\n",
       "        Cardiomegaly  Lung Opacity  Lung Lesion  ...  corner_193  corner_194  \\\n",
       "1               -1.0           1.0          NaN  ...           0           0   \n",
       "5                NaN           NaN          NaN  ...           0           0   \n",
       "6                NaN           NaN          NaN  ...           0           0   \n",
       "7                0.0           NaN          NaN  ...           0           0   \n",
       "8                0.0           NaN          NaN  ...           0           0   \n",
       "...              ...           ...          ...  ...         ...         ...   \n",
       "223403           1.0           NaN          NaN  ...           0           0   \n",
       "223405           NaN           1.0          NaN  ...           0           0   \n",
       "223407           NaN           NaN          NaN  ...           0           0   \n",
       "223409           NaN          -1.0          NaN  ...           0           0   \n",
       "223410           NaN          -1.0          NaN  ...           0           0   \n",
       "\n",
       "        corner_195  corner_196  corner_197  corner_198  corner_199  \\\n",
       "1                0           0           0           0           0   \n",
       "5                0           0           0           0           0   \n",
       "6                0           0           0           0           0   \n",
       "7                0           0           0           0           0   \n",
       "8                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "223403           0           0           0           0           0   \n",
       "223405           0           0           0           0           0   \n",
       "223407           0           0           0           0           0   \n",
       "223409           0           0           0           0           0   \n",
       "223410           0           0           0           0           0   \n",
       "\n",
       "        Right_Lung_Intensity  Left_Lung_Intensity  Asymmetry  \n",
       "1                 110.128293            96.570501   0.596201  \n",
       "5                  80.388532            75.504396   0.270156  \n",
       "6                        NaN                  NaN        NaN  \n",
       "7                  70.260511            79.038964   0.225228  \n",
       "8                        NaN                  NaN        NaN  \n",
       "...                      ...                  ...        ...  \n",
       "223403             95.301345            94.698435   0.285247  \n",
       "223405             64.932217            61.532157   0.267634  \n",
       "223407            143.463986            76.111103   0.727078  \n",
       "223409             62.346834            91.663944   0.368473  \n",
       "223410             74.248186            95.215829   0.319442  \n",
       "\n",
       "[133211 rows x 478 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "train_data = pd.get_dummies(train_data, columns=['Sex'])\n",
    "train_data = pd.get_dummies(train_data, columns=['Frontal/Lateral'])\n",
    "train_data = pd.get_dummies(train_data, columns=['AP/PA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>...</th>\n",
       "      <th>Asymmetry</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Sex_Unknown</th>\n",
       "      <th>Frontal/Lateral_Frontal</th>\n",
       "      <th>Frontal/Lateral_Lateral</th>\n",
       "      <th>AP/PA_AP</th>\n",
       "      <th>AP/PA_LL</th>\n",
       "      <th>AP/PA_PA</th>\n",
       "      <th>AP/PA_RL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368473</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133211 rows × 484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path  Age  No Finding  \\\n",
       "1       CheXpert-v1.0-small/train/patient00002/study2/...   87         NaN   \n",
       "5       CheXpert-v1.0-small/train/patient00004/study1/...   20         1.0   \n",
       "6       CheXpert-v1.0-small/train/patient00004/study1/...   20         1.0   \n",
       "7       CheXpert-v1.0-small/train/patient00005/study1/...   33         1.0   \n",
       "8       CheXpert-v1.0-small/train/patient00005/study1/...   33         1.0   \n",
       "...                                                   ...  ...         ...   \n",
       "223403  CheXpert-v1.0-small/train/patient64533/study1/...   75         NaN   \n",
       "223405  CheXpert-v1.0-small/train/patient64534/study1/...   63         NaN   \n",
       "223407  CheXpert-v1.0-small/train/patient64536/study2/...   61         NaN   \n",
       "223409  CheXpert-v1.0-small/train/patient64537/study2/...   59         NaN   \n",
       "223410  CheXpert-v1.0-small/train/patient64537/study1/...   59         NaN   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  \\\n",
       "1                              NaN          -1.0           1.0          NaN   \n",
       "5                              0.0           NaN           NaN          NaN   \n",
       "6                              0.0           NaN           NaN          NaN   \n",
       "7                              NaN           0.0           NaN          NaN   \n",
       "8                              NaN           0.0           NaN          NaN   \n",
       "...                            ...           ...           ...          ...   \n",
       "223403                         NaN           1.0           NaN          NaN   \n",
       "223405                         NaN           NaN           1.0          NaN   \n",
       "223407                         NaN           NaN           NaN          NaN   \n",
       "223409                         NaN           NaN          -1.0          NaN   \n",
       "223410                         NaN           NaN          -1.0          NaN   \n",
       "\n",
       "        Edema  Consolidation  Pneumonia  ...  Asymmetry  Sex_Female  Sex_Male  \\\n",
       "1        -1.0           -1.0        NaN  ...   0.596201           1         0   \n",
       "5         NaN            0.0        NaN  ...   0.270156           1         0   \n",
       "6         NaN            0.0        NaN  ...        NaN           1         0   \n",
       "7         NaN            0.0        NaN  ...   0.225228           0         1   \n",
       "8         NaN            0.0        NaN  ...        NaN           0         1   \n",
       "...       ...            ...        ...  ...        ...         ...       ...   \n",
       "223403    1.0            NaN        NaN  ...   0.285247           0         1   \n",
       "223405    NaN            NaN        NaN  ...   0.267634           0         1   \n",
       "223407    1.0            NaN        NaN  ...   0.727078           1         0   \n",
       "223409    NaN            NaN        NaN  ...   0.368473           0         1   \n",
       "223410    NaN            NaN        0.0  ...   0.319442           0         1   \n",
       "\n",
       "        Sex_Unknown  Frontal/Lateral_Frontal  Frontal/Lateral_Lateral  \\\n",
       "1                 0                        1                        0   \n",
       "5                 0                        1                        0   \n",
       "6                 0                        0                        1   \n",
       "7                 0                        1                        0   \n",
       "8                 0                        0                        1   \n",
       "...             ...                      ...                      ...   \n",
       "223403            0                        1                        0   \n",
       "223405            0                        1                        0   \n",
       "223407            0                        1                        0   \n",
       "223409            0                        1                        0   \n",
       "223410            0                        1                        0   \n",
       "\n",
       "        AP/PA_AP  AP/PA_LL  AP/PA_PA  AP/PA_RL  \n",
       "1              1         0         0         0  \n",
       "5              0         0         1         0  \n",
       "6              0         0         0         0  \n",
       "7              0         0         1         0  \n",
       "8              0         0         0         0  \n",
       "...          ...       ...       ...       ...  \n",
       "223403         1         0         0         0  \n",
       "223405         1         0         0         0  \n",
       "223407         1         0         0         0  \n",
       "223409         1         0         0         0  \n",
       "223410         1         0         0         0  \n",
       "\n",
       "[133211 rows x 484 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data(train_data, feature_cols, test_size=0.2, random_state=42, \n",
    "                pca=False, pca_components=0.95, impute_strategy='mean'):\n",
    "    \"\"\"\n",
    "    Prepares data for machine learning tasks.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: DataFrame containing features and target\n",
    "    - feature_cols: List of feature column names to use\n",
    "    - test_size: Proportion of data for testing (default 0.2)\n",
    "    - random_state: Random seed for reproducibility\n",
    "    - pca: Whether to apply PCA (default False)\n",
    "    - pca_components: Number of components or variance to retain\n",
    "    - impute_strategy: Strategy for handling missing values ('mean', 'median', etc.)\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test: Prepared feature arrays\n",
    "    - y_train, y_test: Encoded target arrays\n",
    "    - encoder: Fitted LabelEncoder (for inverse transform if needed)\n",
    "    - imputer: Fitted imputer (for new data)\n",
    "    - scaler: Fitted scaler (if PCA=True)\n",
    "    - pca: Fitted PCA object (if PCA=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate inputs\n",
    "    if not isinstance(train_data, pd.DataFrame):\n",
    "        raise ValueError(\"train_data must be a pandas DataFrame\")\n",
    "    if not all(col in train_data.columns for col in feature_cols):\n",
    "        raise ValueError(\"Some feature_cols not found in train_data\")\n",
    "    \n",
    "    # Remove rows with missing target values\n",
    "    train_data = train_data.dropna(subset=['Pleural Effusion'])\n",
    "    \n",
    "    # Split features and target\n",
    "    X = train_data[feature_cols].copy()  # Explicit copy to avoid SettingWithCopyWarning\n",
    "    y = train_data['Pleural Effusion']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Encode target variable\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    y_test_encoded = encoder.transform(y_test)\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy=impute_strategy)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    # Initialize return objects\n",
    "    scaler, pca_obj = None, None\n",
    "    \n",
    "    if pca:\n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "        X_test_scaled = scaler.transform(X_test_imputed)\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca_obj = PCA(n_components=pca_components)\n",
    "        X_train_pca = pca_obj.fit_transform(X_train_scaled)\n",
    "        X_test_pca = pca_obj.transform(X_test_scaled)\n",
    "        \n",
    "        print(f\"PCA: Retained {pca_obj.n_components_} components explaining \"\n",
    "              f\"{100*pca_obj.explained_variance_ratio_.sum():.1f}% variance\")\n",
    "        \n",
    "        return (X_train_pca, X_test_pca, y_train_encoded, y_test_encoded, \n",
    "                encoder, imputer, scaler, pca_obj)\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed, y_train_encoded, y_test_encoded, encoder, imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def run_xgboost_experiment(X_train, y_train, X_test, y_test):\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', objective='multi:softprob', num_class=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    # Assuming you want to treat the problem as binary for ROC AUC purposes\n",
    "    auc_score = roc_auc_score(y_test, y_prob, multi_class='ovo')  # One-vs-One strategy for multi-class ROC\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESNET\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Add, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# def build_resnet_model(input_shape, num_classes):\n",
    "#     inputs = Input(shape=(input_shape,))\n",
    "#     x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = ReLU()(x)\n",
    "\n",
    "#     for _ in range(3):  # Increased depth\n",
    "#         x_shortcut = x\n",
    "#         x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = ReLU()(x)\n",
    "#         x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = Add()([x, x_shortcut])\n",
    "#         x = ReLU()(x)\n",
    "\n",
    "#     x = Dense(32)(x)\n",
    "#     x = ReLU()(x)\n",
    "#     x = Dropout(0.5)(x)  # Regularization to prevent overfitting\n",
    "#     outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# def train_predict_evaluate_resnet(X_train, y_train, X_test, y_test):\n",
    "#     # Replace NaNs with a placeholder and use an indicator for missing values\n",
    "#     for column in X_train.columns:\n",
    "#         X_train[column + '_missing'] = X_train[column].isna().astype(int)\n",
    "#         X_train[column].fillna(-999, inplace=True)  # Placeholder value\n",
    "    \n",
    "#     for column in X_test.columns:\n",
    "#         X_test[column + '_missing'] = X_test[column].isna().astype(int)\n",
    "#         X_test[column].fillna(-999, inplace=True)  # Placeholder value\n",
    "\n",
    "#     num_features = X_train.shape[1]\n",
    "#     num_classes = len(set(y_train))\n",
    "\n",
    "#     # Build and train the ResNet model\n",
    "#     model = build_resnet_model(num_features, num_classes)\n",
    "#     model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "#     # Predict probabilities on the test set and calculate AUC\n",
    "#     y_prob = model.predict(X_test)\n",
    "#     auc_score = roc_auc_score(y_test, y_prob, multi_class='ovo')\n",
    "\n",
    "#     return auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>...</th>\n",
       "      <th>Asymmetry</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Sex_Unknown</th>\n",
       "      <th>Frontal/Lateral_Frontal</th>\n",
       "      <th>Frontal/Lateral_Lateral</th>\n",
       "      <th>AP/PA_AP</th>\n",
       "      <th>AP/PA_LL</th>\n",
       "      <th>AP/PA_PA</th>\n",
       "      <th>AP/PA_RL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368473</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133211 rows × 484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path  Age  No Finding  \\\n",
       "1       CheXpert-v1.0-small/train/patient00002/study2/...   87         NaN   \n",
       "5       CheXpert-v1.0-small/train/patient00004/study1/...   20         1.0   \n",
       "6       CheXpert-v1.0-small/train/patient00004/study1/...   20         1.0   \n",
       "7       CheXpert-v1.0-small/train/patient00005/study1/...   33         1.0   \n",
       "8       CheXpert-v1.0-small/train/patient00005/study1/...   33         1.0   \n",
       "...                                                   ...  ...         ...   \n",
       "223403  CheXpert-v1.0-small/train/patient64533/study1/...   75         NaN   \n",
       "223405  CheXpert-v1.0-small/train/patient64534/study1/...   63         NaN   \n",
       "223407  CheXpert-v1.0-small/train/patient64536/study2/...   61         NaN   \n",
       "223409  CheXpert-v1.0-small/train/patient64537/study2/...   59         NaN   \n",
       "223410  CheXpert-v1.0-small/train/patient64537/study1/...   59         NaN   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  \\\n",
       "1                              NaN          -1.0           1.0          NaN   \n",
       "5                              0.0           NaN           NaN          NaN   \n",
       "6                              0.0           NaN           NaN          NaN   \n",
       "7                              NaN           0.0           NaN          NaN   \n",
       "8                              NaN           0.0           NaN          NaN   \n",
       "...                            ...           ...           ...          ...   \n",
       "223403                         NaN           1.0           NaN          NaN   \n",
       "223405                         NaN           NaN           1.0          NaN   \n",
       "223407                         NaN           NaN           NaN          NaN   \n",
       "223409                         NaN           NaN          -1.0          NaN   \n",
       "223410                         NaN           NaN          -1.0          NaN   \n",
       "\n",
       "        Edema  Consolidation  Pneumonia  ...  Asymmetry  Sex_Female  Sex_Male  \\\n",
       "1        -1.0           -1.0        NaN  ...   0.596201           1         0   \n",
       "5         NaN            0.0        NaN  ...   0.270156           1         0   \n",
       "6         NaN            0.0        NaN  ...        NaN           1         0   \n",
       "7         NaN            0.0        NaN  ...   0.225228           0         1   \n",
       "8         NaN            0.0        NaN  ...        NaN           0         1   \n",
       "...       ...            ...        ...  ...        ...         ...       ...   \n",
       "223403    1.0            NaN        NaN  ...   0.285247           0         1   \n",
       "223405    NaN            NaN        NaN  ...   0.267634           0         1   \n",
       "223407    1.0            NaN        NaN  ...   0.727078           1         0   \n",
       "223409    NaN            NaN        NaN  ...   0.368473           0         1   \n",
       "223410    NaN            NaN        0.0  ...   0.319442           0         1   \n",
       "\n",
       "        Sex_Unknown  Frontal/Lateral_Frontal  Frontal/Lateral_Lateral  \\\n",
       "1                 0                        1                        0   \n",
       "5                 0                        1                        0   \n",
       "6                 0                        0                        1   \n",
       "7                 0                        1                        0   \n",
       "8                 0                        0                        1   \n",
       "...             ...                      ...                      ...   \n",
       "223403            0                        1                        0   \n",
       "223405            0                        1                        0   \n",
       "223407            0                        1                        0   \n",
       "223409            0                        1                        0   \n",
       "223410            0                        1                        0   \n",
       "\n",
       "        AP/PA_AP  AP/PA_LL  AP/PA_PA  AP/PA_RL  \n",
       "1              1         0         0         0  \n",
       "5              0         0         1         0  \n",
       "6              0         0         0         0  \n",
       "7              0         0         1         0  \n",
       "8              0         0         0         0  \n",
       "...          ...       ...       ...       ...  \n",
       "223403         1         0         0         0  \n",
       "223405         1         0         0         0  \n",
       "223407         1         0         0         0  \n",
       "223409         1         0         0         0  \n",
       "223410         1         0         0         0  \n",
       "\n",
       "[133211 rows x 484 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Image Loading Function ---\n",
    "def load_images(image_paths, base_path='', img_size=(224, 224)):\n",
    "    images = []\n",
    "    for img_rel_path in image_paths:\n",
    "        full_path = os.path.join(base_path, img_rel_path)\n",
    "        try:\n",
    "            img = Image.open(full_path).convert('L')  # Convert to grayscale\n",
    "            img = img.resize(img_size)\n",
    "            img_array = np.array(img) / 255.0  # Normalize [0, 1]\n",
    "            img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
    "            images.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {full_path}: {e}\")\n",
    "            images.append(np.zeros((*img_size, 1)))  # Blank image if error\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "# --- Numerical Features Loading ---\n",
    "def load_tabular_features(df):\n",
    "    tabular_features = df[['Age', 'sex_male', 'sex_female', 'sex_unknown'] +\n",
    "                           [col for col in df.columns if col.startswith('corner')] +\n",
    "                           [col for col in df.columns if col.startswith('hist')]]\n",
    "    return tabular_features.values.astype(np.float32)\n",
    "\n",
    "# --- Build Multi-Input Model ---\n",
    "def build_multi_input_model(image_shape, tabular_shape):\n",
    "    # Image branch\n",
    "    image_input = Input(shape=image_shape)\n",
    "    base_cnn = ResNet50(weights=None, include_top=False, input_tensor=image_input)\n",
    "    x_img = GlobalAveragePooling2D()(base_cnn.output)\n",
    "\n",
    "    # Tabular branch\n",
    "    tabular_input = Input(shape=(tabular_shape,))\n",
    "    x_tab = Dense(128, activation='relu')(tabular_input)\n",
    "    x_tab = Dense(64, activation='relu')(x_tab)\n",
    "\n",
    "    # Merge\n",
    "    combined = concatenate([x_img, x_tab])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "    model = Model(inputs=[image_input, tabular_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# --- MAIN PIPELINE ---\n",
    "def main_pipeline(train_data, base_image_path):\n",
    "    # 1. Load images\n",
    "    print(\"Loading images...\")\n",
    "    images_array = load_images(train_data['Path'], base_path=base_image_path, img_size=(224, 224))\n",
    "    print(\"Images loaded:\", images_array.shape)\n",
    "\n",
    "    # 2. Load tabular features\n",
    "    print(\"Loading numerical features...\")\n",
    "    tabular_array = load_tabular_features(train_data)\n",
    "    print(\"Numerical features loaded:\", tabular_array.shape)\n",
    "\n",
    "    # 3. Normalize tabular features\n",
    "    scaler = StandardScaler()\n",
    "    tabular_array = scaler.fit_transform(tabular_array)\n",
    "\n",
    "    # 4. Load labels\n",
    "    labels_array = train_data['Label'].values  # Make sure you have 'Label' column\n",
    "\n",
    "    # 5. Train-test split\n",
    "    X_img_train, X_img_val, X_tab_train, X_tab_val, y_train, y_val = train_test_split(\n",
    "        images_array, tabular_array, labels_array, test_size=0.2, random_state=42, stratify=labels_array\n",
    "    )\n",
    "\n",
    "    # 6. Build the model\n",
    "    print(\"Building model...\")\n",
    "    model = build_multi_input_model(image_shape=(224, 224, 1), tabular_shape=tabular_array.shape[1])\n",
    "    model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 7. Train the model\n",
    "    print(\"Training model...\")\n",
    "    model.fit([X_img_train, X_tab_train], y_train,\n",
    "              validation_data=([X_img_val, X_tab_val], y_val),\n",
    "              epochs=15, batch_size=32)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main_pipeline(train_data, base_image_path='/path/to/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Path', 'Age', 'No Finding', 'Enlarged Cardiomediastinum',\n",
       "       'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation',\n",
       "       'Pneumonia',\n",
       "       ...\n",
       "       'Asymmetry', 'Sex_Female', 'Sex_Male', 'Sex_Unknown',\n",
       "       'Frontal/Lateral_Frontal', 'Frontal/Lateral_Lateral', 'AP/PA_AP',\n",
       "       'AP/PA_LL', 'AP/PA_PA', 'AP/PA_RL'],\n",
       "      dtype='object', length=484)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST WITHOUT CLINICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUC: 0.650409677457851\n"
     ]
    }
   ],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "# train_data_no_clinical = train_data.drop(['Pleural Effusion', 'Path','Right_Lung_Intensity', 'Left_Lung_Intensity', 'Asymmetry', ], axis=1)\n",
    "# feature_columns = train_data_no_clinical.columns  # Modify as needed\n",
    "fixed_columns = ['Age', 'Sex_Male', 'Sex_Female', 'Sex_Unknown']\n",
    "\n",
    "# Select columns that start with 'corner' or 'hist'\n",
    "pattern_columns = [col for col in train_data.columns if col.startswith('corner') or col.startswith('hist')]\n",
    "\n",
    "# Combine all desired columns\n",
    "feature_columns = fixed_columns + pattern_columns\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test, encoder, imputer = prepare_data(train_data, feature_columns, pca=False)\n",
    "\n",
    "# Run XGBoost experiment\n",
    "xgb_auc = run_xgboost_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"XGBoost AUC:\", xgb_auc)\n",
    "# print(\"ResNet AUC:\", resnet_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ce8c4c07e950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_predict_evaluate_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ResNet Model AUC Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-dc8adcc09cb6>\u001b[0m in \u001b[0;36mtrain_predict_evaluate_resnet\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_predict_evaluate_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Replace NaNs with a placeholder and use an indicator for missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_missing'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Placeholder value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "auc_score = train_predict_evaluate_resnet(X_train, y_train, X_test, y_test)\n",
    "print(\"ResNet Model AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST WITH CLINICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_clinical = train_data.drop(['Pleural Effusion', 'Path'], axis=1)\n",
    "feature_columns = train_data_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test = prepare_data(train_data, feature_columns, pca=False)\n",
    "\n",
    "# Run XGBoost experiment\n",
    "xgb_auc = run_xgboost_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# For ResNet, ensure you have the appropriate setup or use another suitable model\n",
    "# resnet_auc = run_resnet_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"XGBoost AUC:\", xgb_auc)\n",
    "# print(\"ResNet AUC:\", resnet_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = train_predict_evaluate_resnet(X_train, y_train, X_test, y_test)\n",
    "print(\"ResNet Model AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_clinical = train_data.drop(['Pleural Effusion', 'Path'], axis=1)\n",
    "feature_columns = train_data_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test = prepare_data(train_data, feature_columns, pca=True)\n",
    "\n",
    "# Run XGBoost experiment\n",
    "xgb_auc = run_xgboost_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# For ResNet, ensure you have the appropriate setup or use another suitable model\n",
    "# resnet_auc = run_resnet_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"XGBoost AUC:\", xgb_auc)\n",
    "# print(\"ResNet AUC:\", resnet_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = train_predict_evaluate_resnet(X_train, y_train, X_test, y_test)\n",
    "print(\"ResNet Model AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subset of columns for an experiment\n",
    "# Correct way to drop multiple columns\n",
    "train_data_no_clinical = train_data.drop(['Pleural Effusion', 'Path','Right_Lung_Intensity', 'Left_Lung_Intensity', 'Asymmetry', ], axis=1)\n",
    "feature_columns = train_data_no_clinical.columns  # Modify as needed\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test = prepare_data(train_data, feature_columns, pca=True)\n",
    "\n",
    "# Run XGBoost experiment\n",
    "xgb_auc = run_xgboost_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"XGBoost AUC:\", xgb_auc)\n",
    "# print(\"ResNet AUC:\", resnet_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = train_predict_evaluate_resnet(X_train, y_train, X_test, y_test)\n",
    "print(\"ResNet Model AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
